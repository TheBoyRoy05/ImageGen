{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36970470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import logging\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from modules import UNet, Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efecb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9f4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    dataloader = get_data(args)\n",
    "\n",
    "    mse = nn.MSELoss()\n",
    "    model = UNet().to(args.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=args.device)\n",
    "    \n",
    "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (images, _) in enumerate(pbar):\n",
    "            images = images.to(args.device)\n",
    "            t = diffusion.sample_timesteps(images.shape[0]).to(args.device)\n",
    "            x_t, noise = diffusion.noise_images(images, t)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            loss = mse(noise, predicted_noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
    "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b8a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args(args=[])\n",
    "    args.run_name = \"DDPM_Uncondtional\"\n",
    "    args.epochs = 500\n",
    "    args.batch_size = 12\n",
    "    args.image_size = 64\n",
    "    args.dataset_path = r\"C:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\landscape_imgs\"\n",
    "    args.device = \"cpu\"\n",
    "    args.lr = 3e-4\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd027604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:36:37 - INFO: Starting epoch 0:\n",
      "  0%|          | 0/360 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mlaunch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m args\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m args\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-4\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     18\u001b[0m t \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39msample_timesteps(images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     19\u001b[0m x_t, noise \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mnoise_images(images, t)\n\u001b[1;32m---> 20\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse(noise, predicted_noise)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\modules.py:134\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[0;32m    133\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m--> 134\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minc1(x)\n\u001b[0;32m    137\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x1, t)\n",
      "File \u001b[1;32mc:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\modules.py:126\u001b[0m, in \u001b[0;36mUNet.pos_encoding\u001b[1;34m(self, t, channels)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpos_encoding\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, channels):\n\u001b[1;32m--> 126\u001b[0m     inv_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m10000\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m channels))\n\u001b[0;32m    127\u001b[0m     pos_enc_a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(t\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m inv_freq)\n\u001b[0;32m    128\u001b[0m     pos_enc_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(t\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m inv_freq)\n",
      "File \u001b[1;32mc:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
