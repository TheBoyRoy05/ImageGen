{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36970470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import logging\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from modules import UNet, Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efecb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9f4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    dataloader = get_data(args)\n",
    "\n",
    "    mse = nn.MSELoss()\n",
    "    model = UNet().to(args.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=args.device)\n",
    "    \n",
    "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (images, _) in enumerate(pbar):\n",
    "            images = images.to(args.device)\n",
    "            t = diffusion.sample_timesteps(images.shape[0]).to(args.device)\n",
    "            x_t, noise = diffusion.noise_images(images, t)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            loss = mse(noise, predicted_noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
    "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b8a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args(args=[])\n",
    "    args.run_name = \"DDPM_Uncondtional\"\n",
    "    args.epochs = 500\n",
    "    args.batch_size = 12\n",
    "    args.image_size = 64\n",
    "    args.dataset_path = r\"C:\\Users\\issac\\OneDrive\\Projects\\ImageGen\\landscape_imgs\"\n",
    "    args.device = \"cpu\"\n",
    "    args.lr = 3e-4\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd027604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:54:05 - INFO: Starting epoch 0:\n",
      "  4%|‚ñç         | 16/360 [07:41<2:45:18, 28.83s/it, MSE=0.686]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
